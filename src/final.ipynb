{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../dataset/upi_fraud_dataset.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_hour</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>category</th>\n",
       "      <th>upi_number</th>\n",
       "      <th>age</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>9957000001</td>\n",
       "      <td>54</td>\n",
       "      <td>66.21</td>\n",
       "      <td>22</td>\n",
       "      <td>49879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>9957000002</td>\n",
       "      <td>15</td>\n",
       "      <td>55.81</td>\n",
       "      <td>14</td>\n",
       "      <td>62668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>9957000003</td>\n",
       "      <td>60</td>\n",
       "      <td>8.68</td>\n",
       "      <td>4</td>\n",
       "      <td>96037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>9957000004</td>\n",
       "      <td>44</td>\n",
       "      <td>89.52</td>\n",
       "      <td>40</td>\n",
       "      <td>29911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>9957000005</td>\n",
       "      <td>72</td>\n",
       "      <td>1.90</td>\n",
       "      <td>38</td>\n",
       "      <td>16421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_hour  trans_day  trans_month  trans_year  category  upi_number  age  \\\n",
       "0           0          1            1        2022        12  9957000001   54   \n",
       "1           1          1            1        2022         3  9957000002   15   \n",
       "2           3          1            1        2022         8  9957000003   60   \n",
       "3           6          1            1        2022         4  9957000004   44   \n",
       "4           6          1            1        2022         0  9957000005   72   \n",
       "\n",
       "   trans_amount  state    zip  fraud_risk  \n",
       "0         66.21     22  49879           0  \n",
       "1         55.81     14  62668           0  \n",
       "2          8.68      4  96037           0  \n",
       "3         89.52     40  29911           0  \n",
       "4          1.90     38  16421           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[ : , : 10].values\n",
    "y = dataset.iloc[ : , 10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2266, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = np.count_nonzero(y_train == 1)\n",
    "valid = np.count_nonzero(y_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud cases in training data = 1348\n",
      "Valid cases in training data = 918\n"
     ]
    }
   ],
   "source": [
    "print('Fraud cases in training data =', fraud)\n",
    "print('Valid cases in training data =', valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11287494,  0.23492331, -0.89608107,  0.        ,  0.0602433 ,\n",
       "         0.68096147,  0.83994401, -0.84340161, -0.45791225, -1.64639185],\n",
       "       [-1.1894848 , -0.92886509,  0.66178275,  0.        , -1.24483613,\n",
       "        -0.3824002 , -0.27301162, -0.83469894,  1.03866827, -0.4058421 ],\n",
       "       [ 1.11287494, -1.02584746,  2.53121934,  0.        ,  0.32125918,\n",
       "        -0.38240085,  1.63491233,  1.40609705, -0.31538077,  0.32896382],\n",
       "       [-1.1894848 ,  0.91379987, -0.89608107,  0.        , -1.24483613,\n",
       "        -1.11969157, -0.3790074 , -0.72010938, -0.24411503,  0.5966091 ],\n",
       "       [ 1.11287494,  0.42888804, -0.89608107,  0.        , -1.76686789,\n",
       "        -1.11969169, -0.8029905 ,  0.14610555,  1.18119975,  1.37176053]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[ : 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99775696, -1.02584746,  0.66178275,  0.        , -1.50585201,\n",
       "        -0.38240103, -0.8029905 , -0.55231661, -0.24411503,  0.60587057],\n",
       "       [-1.30460278,  1.6896588 , -0.89608107,  0.        , -0.72280436,\n",
       "        -0.93972315,  0.09797359, -0.10066076, -1.66942982,  1.78976412],\n",
       "       [-1.07436681,  0.33190567, -0.27293554,  0.        , -1.24483613,\n",
       "        -0.38240071, -0.96198416, -0.63173177,  0.46854236, -1.33247671],\n",
       "       [ 0.53728501, -1.21981219,  0.66178275,  0.        ,  1.10430683,\n",
       "         1.8381786 ,  0.94593979,  1.36440214, -0.24411503,  0.62521842],\n",
       "       [ 0.07681306, -1.02584746, -0.27293554,  0.        , -0.20077259,\n",
       "        -0.38240113, -0.22001374, -0.63409578, -0.67170947,  0.8568677 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[ : 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression(random_state = 0)\n",
    "LR_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lr = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8025\n"
     ]
    }
   ],
   "source": [
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NEAREST NEIGHBORS (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "KNN_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KNN_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINE (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM_model = SVC(kernel = 'linear', random_state = 0)\n",
    "SVM_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVM_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_svm = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "print(acc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NB_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nb = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "print(acc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_model = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DT_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dt = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9475\n"
     ]
    }
   ],
   "source": [
    "print(acc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier()\n",
    "RF_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n"
     ]
    }
   ],
   "source": [
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVOLUTIONAL NEURAL NETWORK (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "CNN_model.add(tf.keras.layers.Dense(64, input_dim = 10, activation = 'relu'))\n",
    "CNN_model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "CNN_model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\TUSHAR HIRAWAT\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "CNN_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2266/2266 [==============================] - 1s 308us/sample - loss: 0.5131 - acc: 0.7410\n",
      "Epoch 2/200\n",
      "2266/2266 [==============================] - 0s 154us/sample - loss: 0.4013 - acc: 0.8129\n",
      "Epoch 3/200\n",
      "2266/2266 [==============================] - 0s 148us/sample - loss: 0.3666 - acc: 0.8327\n",
      "Epoch 4/200\n",
      "2266/2266 [==============================] - 0s 96us/sample - loss: 0.3413 - acc: 0.8380\n",
      "Epoch 5/200\n",
      "2266/2266 [==============================] - 0s 135us/sample - loss: 0.3274 - acc: 0.8539\n",
      "Epoch 6/200\n",
      "2266/2266 [==============================] - 0s 113us/sample - loss: 0.3200 - acc: 0.8663\n",
      "Epoch 7/200\n",
      "2266/2266 [==============================] - 0s 105us/sample - loss: 0.3051 - acc: 0.8663\n",
      "Epoch 8/200\n",
      "2266/2266 [==============================] - 0s 118us/sample - loss: 0.3034 - acc: 0.8619\n",
      "Epoch 9/200\n",
      "2266/2266 [==============================] - 0s 103us/sample - loss: 0.2981 - acc: 0.8689\n",
      "Epoch 10/200\n",
      "2266/2266 [==============================] - 0s 100us/sample - loss: 0.2908 - acc: 0.8760\n",
      "Epoch 11/200\n",
      "2266/2266 [==============================] - 0s 131us/sample - loss: 0.2874 - acc: 0.8725\n",
      "Epoch 12/200\n",
      "2266/2266 [==============================] - 0s 96us/sample - loss: 0.2881 - acc: 0.8725\n",
      "Epoch 13/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.2808 - acc: 0.8760\n",
      "Epoch 14/200\n",
      "2266/2266 [==============================] - 0s 114us/sample - loss: 0.2795 - acc: 0.8747\n",
      "Epoch 15/200\n",
      "2266/2266 [==============================] - 0s 101us/sample - loss: 0.2763 - acc: 0.8804\n",
      "Epoch 16/200\n",
      "2266/2266 [==============================] - 0s 103us/sample - loss: 0.2748 - acc: 0.8747\n",
      "Epoch 17/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.2706 - acc: 0.8822\n",
      "Epoch 18/200\n",
      "2266/2266 [==============================] - 0s 111us/sample - loss: 0.2659 - acc: 0.8822\n",
      "Epoch 19/200\n",
      "2266/2266 [==============================] - 0s 99us/sample - loss: 0.2639 - acc: 0.8791\n",
      "Epoch 20/200\n",
      "2266/2266 [==============================] - 0s 139us/sample - loss: 0.2588 - acc: 0.8883\n",
      "Epoch 21/200\n",
      "2266/2266 [==============================] - 0s 102us/sample - loss: 0.2647 - acc: 0.8826\n",
      "Epoch 22/200\n",
      "2266/2266 [==============================] - 0s 136us/sample - loss: 0.2584 - acc: 0.8883\n",
      "Epoch 23/200\n",
      "2266/2266 [==============================] - 0s 134us/sample - loss: 0.2531 - acc: 0.8848\n",
      "Epoch 24/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.2506 - acc: 0.8914\n",
      "Epoch 25/200\n",
      "2266/2266 [==============================] - 0s 200us/sample - loss: 0.2509 - acc: 0.8906\n",
      "Epoch 26/200\n",
      "2266/2266 [==============================] - 0s 177us/sample - loss: 0.2523 - acc: 0.8848\n",
      "Epoch 27/200\n",
      "2266/2266 [==============================] - 0s 180us/sample - loss: 0.2464 - acc: 0.8936\n",
      "Epoch 28/200\n",
      "2266/2266 [==============================] - 0s 183us/sample - loss: 0.2414 - acc: 0.8892\n",
      "Epoch 29/200\n",
      "2266/2266 [==============================] - 0s 196us/sample - loss: 0.2361 - acc: 0.9003\n",
      "Epoch 30/200\n",
      "2266/2266 [==============================] - 0s 125us/sample - loss: 0.2365 - acc: 0.8989\n",
      "Epoch 31/200\n",
      "2266/2266 [==============================] - 0s 113us/sample - loss: 0.2331 - acc: 0.9020\n",
      "Epoch 32/200\n",
      "2266/2266 [==============================] - 0s 135us/sample - loss: 0.2341 - acc: 0.8994\n",
      "Epoch 33/200\n",
      "2266/2266 [==============================] - 0s 176us/sample - loss: 0.2322 - acc: 0.9029\n",
      "Epoch 34/200\n",
      "2266/2266 [==============================] - 0s 127us/sample - loss: 0.2248 - acc: 0.9011\n",
      "Epoch 35/200\n",
      "2266/2266 [==============================] - 0s 127us/sample - loss: 0.2276 - acc: 0.8985\n",
      "Epoch 36/200\n",
      "2266/2266 [==============================] - 0s 170us/sample - loss: 0.2223 - acc: 0.8976\n",
      "Epoch 37/200\n",
      "2266/2266 [==============================] - 0s 132us/sample - loss: 0.2188 - acc: 0.9064\n",
      "Epoch 38/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.2187 - acc: 0.9051\n",
      "Epoch 39/200\n",
      "2266/2266 [==============================] - 0s 140us/sample - loss: 0.2144 - acc: 0.9113\n",
      "Epoch 40/200\n",
      "2266/2266 [==============================] - 0s 112us/sample - loss: 0.2128 - acc: 0.9109\n",
      "Epoch 41/200\n",
      "2266/2266 [==============================] - 0s 120us/sample - loss: 0.2157 - acc: 0.9078\n",
      "Epoch 42/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.2093 - acc: 0.9104\n",
      "Epoch 43/200\n",
      "2266/2266 [==============================] - 0s 130us/sample - loss: 0.2029 - acc: 0.9126\n",
      "Epoch 44/200\n",
      "2266/2266 [==============================] - 0s 108us/sample - loss: 0.2035 - acc: 0.9139\n",
      "Epoch 45/200\n",
      "2266/2266 [==============================] - 0s 115us/sample - loss: 0.2023 - acc: 0.9170\n",
      "Epoch 46/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.1988 - acc: 0.9126\n",
      "Epoch 47/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.1977 - acc: 0.9166\n",
      "Epoch 48/200\n",
      "2266/2266 [==============================] - 0s 112us/sample - loss: 0.1945 - acc: 0.9197\n",
      "Epoch 49/200\n",
      "2266/2266 [==============================] - 0s 109us/sample - loss: 0.1925 - acc: 0.9179\n",
      "Epoch 50/200\n",
      "2266/2266 [==============================] - 0s 111us/sample - loss: 0.1915 - acc: 0.9179\n",
      "Epoch 51/200\n",
      "2266/2266 [==============================] - 0s 112us/sample - loss: 0.1842 - acc: 0.9219\n",
      "Epoch 52/200\n",
      "2266/2266 [==============================] - 0s 102us/sample - loss: 0.1827 - acc: 0.9197\n",
      "Epoch 53/200\n",
      "2266/2266 [==============================] - 0s 124us/sample - loss: 0.1800 - acc: 0.9223\n",
      "Epoch 54/200\n",
      "2266/2266 [==============================] - 0s 109us/sample - loss: 0.1811 - acc: 0.9250\n",
      "Epoch 55/200\n",
      "2266/2266 [==============================] - 0s 129us/sample - loss: 0.1798 - acc: 0.9241\n",
      "Epoch 56/200\n",
      "2266/2266 [==============================] - 0s 115us/sample - loss: 0.1741 - acc: 0.9250\n",
      "Epoch 57/200\n",
      "2266/2266 [==============================] - 0s 127us/sample - loss: 0.1719 - acc: 0.9272\n",
      "Epoch 58/200\n",
      "2266/2266 [==============================] - 0s 100us/sample - loss: 0.1727 - acc: 0.9259\n",
      "Epoch 59/200\n",
      "2266/2266 [==============================] - 0s 130us/sample - loss: 0.1706 - acc: 0.9303\n",
      "Epoch 60/200\n",
      "2266/2266 [==============================] - 0s 111us/sample - loss: 0.1679 - acc: 0.9312\n",
      "Epoch 61/200\n",
      "2266/2266 [==============================] - 0s 114us/sample - loss: 0.1660 - acc: 0.9360\n",
      "Epoch 62/200\n",
      "2266/2266 [==============================] - 0s 104us/sample - loss: 0.1638 - acc: 0.9312\n",
      "Epoch 63/200\n",
      "2266/2266 [==============================] - 0s 104us/sample - loss: 0.1596 - acc: 0.9365\n",
      "Epoch 64/200\n",
      "2266/2266 [==============================] - 0s 119us/sample - loss: 0.1607 - acc: 0.9351\n",
      "Epoch 65/200\n",
      "2266/2266 [==============================] - 0s 100us/sample - loss: 0.1591 - acc: 0.9369\n",
      "Epoch 66/200\n",
      "2266/2266 [==============================] - 0s 134us/sample - loss: 0.1584 - acc: 0.9373\n",
      "Epoch 67/200\n",
      "2266/2266 [==============================] - 0s 129us/sample - loss: 0.1521 - acc: 0.9400\n",
      "Epoch 68/200\n",
      "2266/2266 [==============================] - 0s 112us/sample - loss: 0.1531 - acc: 0.9387\n",
      "Epoch 69/200\n",
      "2266/2266 [==============================] - 0s 133us/sample - loss: 0.1506 - acc: 0.9373\n",
      "Epoch 70/200\n",
      "2266/2266 [==============================] - 0s 160us/sample - loss: 0.1475 - acc: 0.9426\n",
      "Epoch 71/200\n",
      "2266/2266 [==============================] - 0s 172us/sample - loss: 0.1471 - acc: 0.9435\n",
      "Epoch 72/200\n",
      "2266/2266 [==============================] - 0s 117us/sample - loss: 0.1415 - acc: 0.9457\n",
      "Epoch 73/200\n",
      "2266/2266 [==============================] - 0s 137us/sample - loss: 0.1413 - acc: 0.9470\n",
      "Epoch 74/200\n",
      "2266/2266 [==============================] - 0s 124us/sample - loss: 0.1409 - acc: 0.9444\n",
      "Epoch 75/200\n",
      "2266/2266 [==============================] - 0s 121us/sample - loss: 0.1371 - acc: 0.9475\n",
      "Epoch 76/200\n",
      "2266/2266 [==============================] - 0s 185us/sample - loss: 0.1380 - acc: 0.9457\n",
      "Epoch 77/200\n",
      "2266/2266 [==============================] - 0s 145us/sample - loss: 0.1352 - acc: 0.9457\n",
      "Epoch 78/200\n",
      "2266/2266 [==============================] - 0s 116us/sample - loss: 0.1337 - acc: 0.9484\n",
      "Epoch 79/200\n",
      "2266/2266 [==============================] - 0s 106us/sample - loss: 0.1321 - acc: 0.9475\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 0s 125us/sample - loss: 0.1306 - acc: 0.9506\n",
      "Epoch 81/200\n",
      "2266/2266 [==============================] - 0s 118us/sample - loss: 0.1269 - acc: 0.9523\n",
      "Epoch 82/200\n",
      "2266/2266 [==============================] - 0s 118us/sample - loss: 0.1244 - acc: 0.9541\n",
      "Epoch 83/200\n",
      "2266/2266 [==============================] - 0s 97us/sample - loss: 0.1213 - acc: 0.9554\n",
      "Epoch 84/200\n",
      "2266/2266 [==============================] - 0s 114us/sample - loss: 0.1203 - acc: 0.9581\n",
      "Epoch 85/200\n",
      "2266/2266 [==============================] - 0s 100us/sample - loss: 0.1193 - acc: 0.9554\n",
      "Epoch 86/200\n",
      "2266/2266 [==============================] - 0s 111us/sample - loss: 0.1184 - acc: 0.9528\n",
      "Epoch 87/200\n",
      "2266/2266 [==============================] - 0s 102us/sample - loss: 0.1192 - acc: 0.9550\n",
      "Epoch 88/200\n",
      "2266/2266 [==============================] - 0s 95us/sample - loss: 0.1149 - acc: 0.9598\n",
      "Epoch 89/200\n",
      "2266/2266 [==============================] - 0s 115us/sample - loss: 0.1187 - acc: 0.9523\n",
      "Epoch 90/200\n",
      "2266/2266 [==============================] - 0s 91us/sample - loss: 0.1137 - acc: 0.9572\n",
      "Epoch 91/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.1092 - acc: 0.9660\n",
      "Epoch 92/200\n",
      "2266/2266 [==============================] - 0s 115us/sample - loss: 0.1125 - acc: 0.9603\n",
      "Epoch 93/200\n",
      "2266/2266 [==============================] - 0s 104us/sample - loss: 0.1031 - acc: 0.9647\n",
      "Epoch 94/200\n",
      "2266/2266 [==============================] - 0s 125us/sample - loss: 0.1061 - acc: 0.9638\n",
      "Epoch 95/200\n",
      "2266/2266 [==============================] - 0s 92us/sample - loss: 0.0979 - acc: 0.9678\n",
      "Epoch 96/200\n",
      "2266/2266 [==============================] - 0s 111us/sample - loss: 0.0992 - acc: 0.9665\n",
      "Epoch 97/200\n",
      "2266/2266 [==============================] - 0s 115us/sample - loss: 0.0968 - acc: 0.9665\n",
      "Epoch 98/200\n",
      "2266/2266 [==============================] - 0s 121us/sample - loss: 0.0959 - acc: 0.9669\n",
      "Epoch 99/200\n",
      "2266/2266 [==============================] - 0s 102us/sample - loss: 0.0943 - acc: 0.9673\n",
      "Epoch 100/200\n",
      "2266/2266 [==============================] - 0s 122us/sample - loss: 0.0933 - acc: 0.9682\n",
      "Epoch 101/200\n",
      "2266/2266 [==============================] - 0s 101us/sample - loss: 0.0933 - acc: 0.9700\n",
      "Epoch 102/200\n",
      "2266/2266 [==============================] - 0s 116us/sample - loss: 0.0897 - acc: 0.9700\n",
      "Epoch 103/200\n",
      "2266/2266 [==============================] - 0s 118us/sample - loss: 0.0839 - acc: 0.9748\n",
      "Epoch 104/200\n",
      "2266/2266 [==============================] - 0s 116us/sample - loss: 0.0867 - acc: 0.9691\n",
      "Epoch 105/200\n",
      "2266/2266 [==============================] - 0s 120us/sample - loss: 0.0844 - acc: 0.9726\n",
      "Epoch 106/200\n",
      "2266/2266 [==============================] - 0s 117us/sample - loss: 0.0827 - acc: 0.9762\n",
      "Epoch 107/200\n",
      "2266/2266 [==============================] - 0s 126us/sample - loss: 0.0789 - acc: 0.9753\n",
      "Epoch 108/200\n",
      "2266/2266 [==============================] - 0s 107us/sample - loss: 0.0811 - acc: 0.9740\n",
      "Epoch 109/200\n",
      "2266/2266 [==============================] - 0s 157us/sample - loss: 0.0790 - acc: 0.9771\n",
      "Epoch 110/200\n",
      "2266/2266 [==============================] - 0s 127us/sample - loss: 0.0780 - acc: 0.9793\n",
      "Epoch 111/200\n",
      "2266/2266 [==============================] - 0s 105us/sample - loss: 0.0754 - acc: 0.9797\n",
      "Epoch 112/200\n",
      "2266/2266 [==============================] - 0s 142us/sample - loss: 0.0746 - acc: 0.9753\n",
      "Epoch 113/200\n",
      "2266/2266 [==============================] - 0s 99us/sample - loss: 0.0750 - acc: 0.9766\n",
      "Epoch 114/200\n",
      "2266/2266 [==============================] - 0s 98us/sample - loss: 0.0752 - acc: 0.9771\n",
      "Epoch 115/200\n",
      "2266/2266 [==============================] - 0s 122us/sample - loss: 0.0708 - acc: 0.9793\n",
      "Epoch 116/200\n",
      "2266/2266 [==============================] - 0s 109us/sample - loss: 0.0715 - acc: 0.9779\n",
      "Epoch 117/200\n",
      "2266/2266 [==============================] - 0s 117us/sample - loss: 0.0709 - acc: 0.9797\n",
      "Epoch 118/200\n",
      "2266/2266 [==============================] - 0s 114us/sample - loss: 0.0687 - acc: 0.9797\n",
      "Epoch 119/200\n",
      "2266/2266 [==============================] - 0s 119us/sample - loss: 0.0676 - acc: 0.9828\n",
      "Epoch 120/200\n",
      "2266/2266 [==============================] - 0s 131us/sample - loss: 0.0666 - acc: 0.9819\n",
      "Epoch 121/200\n",
      "2266/2266 [==============================] - 0s 107us/sample - loss: 0.0615 - acc: 0.9841\n",
      "Epoch 122/200\n",
      "2266/2266 [==============================] - 0s 109us/sample - loss: 0.0625 - acc: 0.9837\n",
      "Epoch 123/200\n",
      "2266/2266 [==============================] - 0s 114us/sample - loss: 0.0610 - acc: 0.9828\n",
      "Epoch 124/200\n",
      "2266/2266 [==============================] - 0s 106us/sample - loss: 0.0615 - acc: 0.9837\n",
      "Epoch 125/200\n",
      "2266/2266 [==============================] - 0s 124us/sample - loss: 0.0576 - acc: 0.9859\n",
      "Epoch 126/200\n",
      "2266/2266 [==============================] - 0s 109us/sample - loss: 0.0587 - acc: 0.9850\n",
      "Epoch 127/200\n",
      "2266/2266 [==============================] - 0s 104us/sample - loss: 0.0533 - acc: 0.9872\n",
      "Epoch 128/200\n",
      "2266/2266 [==============================] - 0s 124us/sample - loss: 0.0568 - acc: 0.9859\n",
      "Epoch 129/200\n",
      "2266/2266 [==============================] - 0s 121us/sample - loss: 0.0577 - acc: 0.9828\n",
      "Epoch 130/200\n",
      "2266/2266 [==============================] - 0s 131us/sample - loss: 0.0543 - acc: 0.9885\n",
      "Epoch 131/200\n",
      "2266/2266 [==============================] - 0s 126us/sample - loss: 0.0568 - acc: 0.9850\n",
      "Epoch 132/200\n",
      "2266/2266 [==============================] - 0s 122us/sample - loss: 0.0508 - acc: 0.9894\n",
      "Epoch 133/200\n",
      "2266/2266 [==============================] - 0s 115us/sample - loss: 0.0521 - acc: 0.9881\n",
      "Epoch 134/200\n",
      "2266/2266 [==============================] - 0s 114us/sample - loss: 0.0472 - acc: 0.9907\n",
      "Epoch 135/200\n",
      "2266/2266 [==============================] - 0s 112us/sample - loss: 0.0483 - acc: 0.9872\n",
      "Epoch 136/200\n",
      "2266/2266 [==============================] - 0s 132us/sample - loss: 0.0460 - acc: 0.9903\n",
      "Epoch 137/200\n",
      "2266/2266 [==============================] - 0s 116us/sample - loss: 0.0469 - acc: 0.9912\n",
      "Epoch 138/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.0437 - acc: 0.9912\n",
      "Epoch 139/200\n",
      "2266/2266 [==============================] - 0s 122us/sample - loss: 0.0417 - acc: 0.9934\n",
      "Epoch 140/200\n",
      "2266/2266 [==============================] - 0s 133us/sample - loss: 0.0441 - acc: 0.9912\n",
      "Epoch 141/200\n",
      "2266/2266 [==============================] - 0s 140us/sample - loss: 0.0423 - acc: 0.9903\n",
      "Epoch 142/200\n",
      "2266/2266 [==============================] - 0s 127us/sample - loss: 0.0397 - acc: 0.9938\n",
      "Epoch 143/200\n",
      "2266/2266 [==============================] - 0s 120us/sample - loss: 0.0437 - acc: 0.9894\n",
      "Epoch 144/200\n",
      "2266/2266 [==============================] - 0s 135us/sample - loss: 0.0405 - acc: 0.9898\n",
      "Epoch 145/200\n",
      "2266/2266 [==============================] - 0s 126us/sample - loss: 0.0404 - acc: 0.9903\n",
      "Epoch 146/200\n",
      "2266/2266 [==============================] - 0s 136us/sample - loss: 0.0374 - acc: 0.9925\n",
      "Epoch 147/200\n",
      "2266/2266 [==============================] - 0s 133us/sample - loss: 0.0380 - acc: 0.9925\n",
      "Epoch 148/200\n",
      "2266/2266 [==============================] - 0s 182us/sample - loss: 0.0367 - acc: 0.9925\n",
      "Epoch 149/200\n",
      "2266/2266 [==============================] - 0s 114us/sample - loss: 0.0391 - acc: 0.9921\n",
      "Epoch 150/200\n",
      "2266/2266 [==============================] - 0s 137us/sample - loss: 0.0434 - acc: 0.9894\n",
      "Epoch 151/200\n",
      "2266/2266 [==============================] - 0s 122us/sample - loss: 0.0395 - acc: 0.9916\n",
      "Epoch 152/200\n",
      "2266/2266 [==============================] - 0s 123us/sample - loss: 0.0380 - acc: 0.9912\n",
      "Epoch 153/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.0326 - acc: 0.9951\n",
      "Epoch 154/200\n",
      "2266/2266 [==============================] - 0s 113us/sample - loss: 0.0300 - acc: 0.9956\n",
      "Epoch 155/200\n",
      "2266/2266 [==============================] - 0s 136us/sample - loss: 0.0322 - acc: 0.9951\n",
      "Epoch 156/200\n",
      "2266/2266 [==============================] - 0s 120us/sample - loss: 0.0309 - acc: 0.9943\n",
      "Epoch 157/200\n",
      "2266/2266 [==============================] - 0s 121us/sample - loss: 0.0288 - acc: 0.9943\n",
      "Epoch 158/200\n",
      "2266/2266 [==============================] - 0s 80us/sample - loss: 0.0324 - acc: 0.9929\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 0s 69us/sample - loss: 0.0375 - acc: 0.9881\n",
      "Epoch 160/200\n",
      "2266/2266 [==============================] - 0s 83us/sample - loss: 0.0304 - acc: 0.9929\n",
      "Epoch 161/200\n",
      "2266/2266 [==============================] - 0s 116us/sample - loss: 0.0345 - acc: 0.9916\n",
      "Epoch 162/200\n",
      "2266/2266 [==============================] - 0s 108us/sample - loss: 0.0266 - acc: 0.9951\n",
      "Epoch 163/200\n",
      "2266/2266 [==============================] - 0s 122us/sample - loss: 0.0267 - acc: 0.9956\n",
      "Epoch 164/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.0282 - acc: 0.9943\n",
      "Epoch 165/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.0304 - acc: 0.9934\n",
      "Epoch 166/200\n",
      "2266/2266 [==============================] - 0s 111us/sample - loss: 0.0319 - acc: 0.9925\n",
      "Epoch 167/200\n",
      "2266/2266 [==============================] - 0s 129us/sample - loss: 0.0250 - acc: 0.9938\n",
      "Epoch 168/200\n",
      "2266/2266 [==============================] - 0s 105us/sample - loss: 0.0226 - acc: 0.9974\n",
      "Epoch 169/200\n",
      "2266/2266 [==============================] - 0s 103us/sample - loss: 0.0211 - acc: 0.9969\n",
      "Epoch 170/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.0239 - acc: 0.9969\n",
      "Epoch 171/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.0202 - acc: 0.9991\n",
      "Epoch 172/200\n",
      "2266/2266 [==============================] - 0s 116us/sample - loss: 0.0207 - acc: 0.9987\n",
      "Epoch 173/200\n",
      "2266/2266 [==============================] - 0s 113us/sample - loss: 0.0221 - acc: 0.9969\n",
      "Epoch 174/200\n",
      "2266/2266 [==============================] - 0s 107us/sample - loss: 0.0280 - acc: 0.9938\n",
      "Epoch 175/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.0201 - acc: 0.9969\n",
      "Epoch 176/200\n",
      "2266/2266 [==============================] - 0s 122us/sample - loss: 0.0203 - acc: 0.9978\n",
      "Epoch 177/200\n",
      "2266/2266 [==============================] - 0s 131us/sample - loss: 0.0208 - acc: 0.9960\n",
      "Epoch 178/200\n",
      "2266/2266 [==============================] - 0s 107us/sample - loss: 0.0209 - acc: 0.9978\n",
      "Epoch 179/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.0195 - acc: 0.9960\n",
      "Epoch 180/200\n",
      "2266/2266 [==============================] - 0s 129us/sample - loss: 0.0197 - acc: 0.9987\n",
      "Epoch 181/200\n",
      "2266/2266 [==============================] - 0s 139us/sample - loss: 0.0204 - acc: 0.9969\n",
      "Epoch 182/200\n",
      "2266/2266 [==============================] - 0s 132us/sample - loss: 0.0200 - acc: 0.9978\n",
      "Epoch 183/200\n",
      "2266/2266 [==============================] - 0s 129us/sample - loss: 0.0176 - acc: 0.9982\n",
      "Epoch 184/200\n",
      "2266/2266 [==============================] - 0s 138us/sample - loss: 0.0164 - acc: 0.9987\n",
      "Epoch 185/200\n",
      "2266/2266 [==============================] - 0s 154us/sample - loss: 0.0145 - acc: 0.9987\n",
      "Epoch 186/200\n",
      "2266/2266 [==============================] - 0s 138us/sample - loss: 0.0146 - acc: 0.9991\n",
      "Epoch 187/200\n",
      "2266/2266 [==============================] - 0s 128us/sample - loss: 0.0178 - acc: 0.9982\n",
      "Epoch 188/200\n",
      "2266/2266 [==============================] - 0s 120us/sample - loss: 0.0162 - acc: 0.9982\n",
      "Epoch 189/200\n",
      "2266/2266 [==============================] - 0s 112us/sample - loss: 0.0161 - acc: 0.9987\n",
      "Epoch 190/200\n",
      "2266/2266 [==============================] - 0s 121us/sample - loss: 0.0158 - acc: 0.9978\n",
      "Epoch 191/200\n",
      "2266/2266 [==============================] - 0s 129us/sample - loss: 0.0158 - acc: 0.9978\n",
      "Epoch 192/200\n",
      "2266/2266 [==============================] - 0s 132us/sample - loss: 0.0166 - acc: 0.9974\n",
      "Epoch 193/200\n",
      "2266/2266 [==============================] - 0s 163us/sample - loss: 0.0537 - acc: 0.9797\n",
      "Epoch 194/200\n",
      "2266/2266 [==============================] - 0s 115us/sample - loss: 0.0283 - acc: 0.9912\n",
      "Epoch 195/200\n",
      "2266/2266 [==============================] - 0s 123us/sample - loss: 0.0255 - acc: 0.9951\n",
      "Epoch 196/200\n",
      "2266/2266 [==============================] - 0s 130us/sample - loss: 0.0134 - acc: 0.9978\n",
      "Epoch 197/200\n",
      "2266/2266 [==============================] - 0s 130us/sample - loss: 0.0125 - acc: 0.9991\n",
      "Epoch 198/200\n",
      "2266/2266 [==============================] - 0s 110us/sample - loss: 0.0119 - acc: 0.9996\n",
      "Epoch 199/200\n",
      "2266/2266 [==============================] - 0s 130us/sample - loss: 0.0122 - acc: 0.9987\n",
      "Epoch 200/200\n",
      "2266/2266 [==============================] - 0s 137us/sample - loss: 0.0104 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e1b6002e8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.fit(x_train, y_train, batch_size = 32, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc_cnn = CNN_model.evaluate(x_train, y_train, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995587\n"
     ]
    }
   ],
   "source": [
    "print(acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CNN_model.predict(x_test)\n",
    "y_pred[y_pred <= 0.5] = 0\n",
    "y_pred[y_pred > 0.5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY COMPARISON OF ALL THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [acc_lr * 100,\n",
    "          acc_knn * 100,\n",
    "          acc_svm * 100,\n",
    "          acc_nb * 100,\n",
    "          acc_dt * 100,\n",
    "          acc_rf * 100,\n",
    "          acc_cnn * 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\",\n",
    "        \"K-Nearest Neighbors\",\n",
    "        \"Support Vector Machine\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"Convolutional Neural Network\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Algorithm Name'] = names\n",
    "df['Accuracy Score (%)'] = scores\n",
    "df = df.sort_values('Accuracy Score (%)', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm Name</th>\n",
       "      <th>Accuracy Score (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>99.955869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>95.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>94.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>81.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>81.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>80.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Algorithm Name  Accuracy Score (%)\n",
       "6  Convolutional Neural Network           99.955869\n",
       "5                 Random Forest           95.500000\n",
       "4                 Decision Tree           94.750000\n",
       "1           K-Nearest Neighbors           83.000000\n",
       "2        Support Vector Machine           81.500000\n",
       "3                   Naive Bayes           81.250000\n",
       "0           Logistic Regression           80.250000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.subplots(figsize = (10, 5))\n",
    "ax = sns.barplot(x = \"Accuracy Score (%)\", y = \"Algorithm Name\", data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING THE BEST TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('../model/project_model1.h5') is False:\n",
    "    CNN_model.save('../model/project_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
